{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIhwoQtF2s2g",
        "outputId": "61a5e0f1-8243-4a1a-85c5-4f820c19ddc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81jpNy293PIc"
      },
      "outputs": [],
      "source": [
        "path = 'GME_with_comments_groupped_text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF0MGd6x4FeT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf\n",
        "from pyspark import  SparkContext\n",
        "from pyspark.sql.types import StructType\n",
        "\n",
        "import pyspark.sql.types as Ts\n",
        "from pyspark.sql import functions as F "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLe5dDJB38B7"
      },
      "outputs": [],
      "source": [
        "conf = SparkConf().setAppName('appName').setMaster('local[*]')\n",
        "sc = SparkContext(conf=conf)\n",
        "spark = SparkSession(sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9xhhAACRg0e",
        "outputId": "97bef706-d9f2-449b-a284-a52b3b555701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+\n",
            "|_c0|      date|likes|comments_num|posts_num|              titles|            comments|            selftext| Open| High|       Low|     Close| Adj Close|   Volume|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+\n",
            "|318|2021-12-25|    6|           0|        6|To my fellow Apes...| I am a bot from ...| So, while we're ...|154.0|155.0|146.020004|152.139999|152.139999|1055500.0|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = spark.read.option(\"delimiter\", \",\")\\\n",
        "                   .option(\"header\", \"true\")\\\n",
        "                   .option(\"multiline\", \"true\")\\\n",
        "                   .option(\"escape\", \"\\\\\")\\\n",
        "                   .option(\"escape\", '\"')\\\n",
        "                   .option(\"quote\", '\"')\\\n",
        "                   .csv(path)\n",
        "data = data.limit(1)\n",
        "data.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1aUlhImNQZw"
      },
      "source": [
        "# Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUyFLERbNczV",
        "outputId": "79dc2cdf-ece8-4182-e3e7-63b2da05eee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EufVtRON1FB"
      },
      "outputs": [],
      "source": [
        "stemmer = nltk.PorterStemmer()\n",
        "lemm = nltk.WordNetLemmatizer()\n",
        "\n",
        "# eng_words = set(nltk.corpus.words.words())\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3ElSOb-N2tb"
      },
      "outputs": [],
      "source": [
        "def cleaning(x):\n",
        "  x = re.sub(r\"\\/r|\\/n|\\/t\", '', x)\n",
        "  x = re.sub(r\"\\\\n|\\\\t|\\\\r\", '', x)\n",
        "  x = re.sub('[^a-zA-Z]',' ', x)\n",
        "  x = re.sub(r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\", ' ', x)\n",
        "  x = str(x).replace(\"\\n\", '')\n",
        "  x = str(x).replace(\"/r\", '')\n",
        "  x = str(x).replace(\"[removed]\", '')\n",
        "  \n",
        "  x=x.lower().split()\n",
        "  # tweet = [w for w in tweet if w in eng_words or not w.isalpha()]\n",
        "  x=[stemmer.stem(word) for word in x if (word not in stop_words)]\n",
        "  # tweet=[lemm.lemmatize(word) for word in tweet if (word not in stop_words)]\n",
        "\n",
        "  return ' '.join(x)\n",
        "\n",
        "cleaning_udf = F.udf( lambda x: cleaning(x), returnType=Ts.StringType() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLruQOTfPuXW",
        "outputId": "af144634-8089-4243-c370-a1591aa27bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+--------------------+\n",
            "|_c0|      date|likes|comments_num|posts_num|              titles|            comments|            selftext| Open| High|       Low|     Close| Adj Close|   Volume|       test|       proc_comments|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+--------------------+\n",
            "|318|2021-12-25|    6|           0|        6|To my fellow Apes...| I am a bot from ...| So, while we're ...|154.0|155.0|146.020004|152.139999|152.139999|1055500.0|{a -> null}|bot wallstreetbet...|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data2 = data.withColumn( 'proc_comments', cleaning_udf('comments') )\n",
        "data2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kRKH8QSNdgz"
      },
      "source": [
        "# Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzY0aldySQuk",
        "outputId": "7c9f51e0-93ee-4395-e9e9-4dc82cb377a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pysentiment2\n",
            "  Downloading pysentiment2-0.1.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=2.0 in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pysentiment2) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=2.0->pysentiment2) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysentiment2) (1.21.6)\n",
            "Installing collected packages: pysentiment2\n",
            "Successfully installed pysentiment2-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pysentiment2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_MwbETDSas8"
      },
      "outputs": [],
      "source": [
        "import pysentiment2 as ps2\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj2XDBVIWytI"
      },
      "outputs": [],
      "source": [
        "lm = ps2.LM()\n",
        "hiv4 = ps2.HIV4()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gILJETGG9CQO"
      },
      "outputs": [],
      "source": [
        "lm_schema = Ts.MapType(\n",
        "    keyType=Ts.StringType(), valueType=Ts.FloatType()\n",
        ")\n",
        "\n",
        "def lm_scoring(x):\n",
        "  token_lm = lm.tokenize(x)\n",
        "  score_lm = lm.get_score(token_lm)\n",
        "  score_lm_2 = {\n",
        "      'Positive': float(score_lm['Positive']),\n",
        "      'Negative': float(score_lm['Negative']),\n",
        "      'Polarity': float(score_lm['Polarity']),\n",
        "      'Subjectivity': float(score_lm['Subjectivity'])\n",
        "  }\n",
        "  return score_lm_2\n",
        "\n",
        "# lm_scor_udf = F.udf( lambda x: lm_scoring(x), returnType=Ts.MapType(keyType=Ts.StringType(), valueType=Ts.StringType() ) )\n",
        "lm_scor_udf = F.udf( lambda x: lm_scoring(x), lm_schema )\n",
        "\n",
        "# lm_scoring(data.rdd.map(lambda x: x.comments).collect()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB4kkEXYHkkd"
      },
      "outputs": [],
      "source": [
        "def hiv4_scoring(x):\n",
        "  token_h4 = lm.tokenize(x)\n",
        "  score_h4 = lm.get_score(token_h4)\n",
        "  score_h4_2 = {\n",
        "      'Positive': float(score_h4['Positive']),\n",
        "      'Negative': float(score_h4['Negative']),\n",
        "      'Polarity': float(score_h4['Polarity']),\n",
        "      'Subjectivity': float(score_h4['Subjectivity'])\n",
        "  }\n",
        "  return score_h4_2\n",
        "\n",
        "h4_scor_udf = F.udf( lambda x: hiv4_scoring(x), returnType=Ts.MapType(Ts.StringType(), valueType=Ts.FloatType() ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRVG7CqfWQHq"
      },
      "outputs": [],
      "source": [
        "def vader_scoring(x):\n",
        "  token_vader = lm.tokenize(x)\n",
        "  score_vader = lm.get_score(token_vader)\n",
        "  score_vader_2 = {\n",
        "      'Positive': float(score_vader['Positive']),\n",
        "      'Negative': float(score_vader['Negative']),\n",
        "      'Polarity': float(score_vader['Polarity']),\n",
        "      'Subjectivity': float(score_vader['Subjectivity'])\n",
        "  }\n",
        "  return score_vader_2\n",
        "  \n",
        "vader_scor_udf = F.udf( lambda x: vader_scoring(x), returnType=Ts.MapType(keyType=Ts.StringType(), valueType=Ts.DoubleType() ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsHMCU1OXR_J",
        "outputId": "9f77528b-6370-46a2-c081-5ef7c8ec7a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+\n",
            "|_c0|      date|likes|comments_num|posts_num|              titles|            comments|            selftext| Open| High|       Low|     Close| Adj Close|   Volume|       test|lm_scor_Positive|lm_scor_Negative|lm_scor_Polarity|lm_scor_Subjectivity|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+\n",
            "|318|2021-12-25|    6|           0|        6|To my fellow Apes...| I am a bot from ...| So, while we're ...|154.0|155.0|146.020004|152.139999|152.139999|1055500.0|{a -> null}|          1694.0|          4354.0|      -0.4398148|          0.07018195|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data2 = data.withColumn( 'comments_lm_scoring_dict', lm_scor_udf(F.col('comments')) )\\\n",
        "            .withColumn( 'lm_scor_Positive', F.col('comments_lm_scoring_dict')['Positive'])\\\n",
        "            .withColumn( 'lm_scor_Negative', F.col('comments_lm_scoring_dict')['Negative'])\\\n",
        "            .withColumn( 'lm_scor_Polarity', F.col('comments_lm_scoring_dict')['Polarity'])\\\n",
        "            .withColumn( 'lm_scor_Subjectivity', F.col('comments_lm_scoring_dict')['Subjectivity'])\\\n",
        "            .drop('comments_lm_scoring_dict')\n",
        "            \n",
        "data2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0iG1XE-KPu0",
        "outputId": "49d2eeab-4f04-478b-d2cf-156b899c27e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+\n",
            "|_c0|      date|likes|comments_num|posts_num|              titles|            comments|            selftext| Open| High|       Low|     Close| Adj Close|   Volume|       test|lm_scor_Positive|lm_scor_Negative|lm_scor_Polarity|lm_scor_Subjectivity|h4_scor_Positive|h4_scor_Negative|h4_scor_Polarity|h4_scor_Subjectivity|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+\n",
            "|318|2021-12-25|    6|           0|        6|To my fellow Apes...| I am a bot from ...| So, while we're ...|154.0|155.0|146.020004|152.139999|152.139999|1055500.0|{a -> null}|          1694.0|          4354.0|      -0.4398148|          0.07018195|          1694.0|          4354.0|      -0.4398148|          0.07018195|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data2 = data2.withColumn( 'comments_h4_scoring_dict', h4_scor_udf(F.col('comments')) )\\\n",
        "            .withColumn( 'h4_scor_Positive', F.col('comments_h4_scoring_dict')['Positive'])\\\n",
        "            .withColumn( 'h4_scor_Negative', F.col('comments_h4_scoring_dict')['Negative'])\\\n",
        "            .withColumn( 'h4_scor_Polarity', F.col('comments_h4_scoring_dict')['Polarity'])\\\n",
        "            .withColumn( 'h4_scor_Subjectivity', F.col('comments_h4_scoring_dict')['Subjectivity'])\\\n",
        "            .drop('comments_h4_scoring_dict')\n",
        "\n",
        "data2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjQkJVbLKklK",
        "outputId": "2fe1e741-fb0b-4579-894c-cfbb8617414a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+-------------------+-------------------+-------------------+-----------------------+\n",
            "|_c0|      date|likes|comments_num|posts_num|              titles|            comments|            selftext| Open| High|       Low|     Close| Adj Close|   Volume|       test|lm_scor_Positive|lm_scor_Negative|lm_scor_Polarity|lm_scor_Subjectivity|h4_scor_Positive|h4_scor_Negative|h4_scor_Polarity|h4_scor_Subjectivity|vader_scor_Positive|vader_scor_Negative|vader_scor_Polarity|vader_scor_Subjectivity|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+-------------------+-------------------+-------------------+-----------------------+\n",
            "|318|2021-12-25|    6|           0|        6|To my fellow Apes...| I am a bot from ...| So, while we're ...|154.0|155.0|146.020004|152.139999|152.139999|1055500.0|{a -> null}|          1694.0|          4354.0|      -0.4398148|          0.07018195|          1694.0|          4354.0|      -0.4398148|          0.07018195|             1694.0|             4354.0|         -0.4398148|             0.07018195|\n",
            "+---+----------+-----+------------+---------+--------------------+--------------------+--------------------+-----+-----+----------+----------+----------+---------+-----------+----------------+----------------+----------------+--------------------+----------------+----------------+----------------+--------------------+-------------------+-------------------+-------------------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data2 = data2.withColumn( 'comments_vader_scoring_dict', h4_scor_udf(F.col('comments')) )\\\n",
        "            .withColumn( 'vader_scor_Positive', F.col('comments_vader_scoring_dict')['Positive'])\\\n",
        "            .withColumn( 'vader_scor_Negative', F.col('comments_vader_scoring_dict')['Negative'])\\\n",
        "            .withColumn( 'vader_scor_Polarity', F.col('comments_vader_scoring_dict')['Polarity'])\\\n",
        "            .withColumn( 'vader_scor_Subjectivity', F.col('comments_vader_scoring_dict')['Subjectivity'])\\\n",
        "            .drop('comments_vader_scoring_dict')\n",
        "\n",
        "data2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0DIm1LyTpBA"
      },
      "outputs": [],
      "source": [
        "data2.write.format(\"csv\").save(\"storage/text_processed.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_clean_incicates.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
